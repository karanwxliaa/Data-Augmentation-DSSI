{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Kinyarwanda TSV dataset\n",
    "data = pd.read_csv('/content/kr_train.tsv', sep='\\t')\n",
    "\n",
    "# Split the dataset into features and target\n",
    "X = data['tweet']\n",
    "y = data['label']\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=11)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=11)\n",
    "\n",
    "# Vectorize the text data using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_val = vectorizer.transform(X_val)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lada_kinyarwanda_tsv(X_train, y_train, model, window_size=5, num_augmented_samples=10):\n",
    "    \"\"\"\n",
    "    Implement LADA approach for the Kinyarwanda TSV dataset.\n",
    "\n",
    "    Args:\n",
    "        X_train (csr_matrix): Training Kinyarwanda text data (TF-IDF vectorized).\n",
    "        y_train (pandas.Series): Training target.\n",
    "        model: The machine learning model to be used for LADA.\n",
    "        window_size (int): Size of the look-ahead window.\n",
    "        num_augmented_samples (int): Number of augmented samples to generate.\n",
    "\n",
    "    Returns:\n",
    "        csr_matrix: Augmented training Kinyarwanda text data.\n",
    "        pandas.Series: Augmented training target.\n",
    "    \"\"\"\n",
    "    # Initialize lists to store augmented data\n",
    "    X_augmented_data = []\n",
    "    X_augmented_indices = []\n",
    "    y_augmented = []  # Use a list to store augmented labels\n",
    "\n",
    "    for i in range(num_augmented_samples):\n",
    "        # Generate a random index within the training set\n",
    "        idx = np.random.randint(0, X_train.shape[0])\n",
    "\n",
    "        # Get the look-ahead window (adjusting for CSR matrix format)\n",
    "        start_idx = X_train.indptr[idx]\n",
    "        end_idx = X_train.indptr[idx + window_size] if idx + window_size < X_train.shape[0] else X_train.indptr[-1]\n",
    "\n",
    "        # Compute the uncertainty score for each sample in the look-ahead window\n",
    "        uncertainty_scores = [uncertainty_score(model, X_train[idx + j]) for j in range(window_size) if idx + j < X_train.shape[0]]\n",
    "\n",
    "        # Select the most informative sample(s) based on the uncertainty scores\n",
    "        most_informative_idx = np.argsort(uncertainty_scores)[-1]\n",
    "\n",
    "        # Extract the most informative sample using CSR matrix properties\n",
    "        most_informative_sample_data = X_train.data[start_idx + most_informative_idx : end_idx]\n",
    "        most_informative_sample_indices = X_train.indices[start_idx + most_informative_idx : end_idx]\n",
    "\n",
    "        # Append to augmented data\n",
    "        X_augmented_data.extend(most_informative_sample_data)\n",
    "        X_augmented_indices.extend(most_informative_sample_indices)\n",
    "        y_augmented.append(y_train.iloc[idx + most_informative_idx]) # Append the corresponding label to the list\n",
    "\n",
    "    # Calculate X_augmented_indptr directly from X_train.indptr\n",
    "    X_augmented_indptr = [0]\n",
    "    cumulative_count = 0\n",
    "    for i in range(len(y_augmented)):\n",
    "        cumulative_count += X_train.indptr[i+1] - X_train.indptr[i]\n",
    "        X_augmented_indptr.append(cumulative_count)\n",
    "\n",
    "    # Create a new CSR matrix from the augmented data\n",
    "    X_augmented = csr_matrix((X_augmented_data, X_augmented_indices, X_augmented_indptr), shape=(len(y_augmented), X_train.shape[1]))\n",
    "\n",
    "    # Convert the list of augmented labels to a Pandas Series\n",
    "    y_augmented = pd.Series(y_augmented)\n",
    "\n",
    "    return X_augmented, y_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_model(model, X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Benchmark the performance of a given model.\n",
    "\n",
    "    Args:\n",
    "        model: The machine learning model to be evaluated.\n",
    "        X_train (csr_matrix): Training Kinyarwanda text data.\n",
    "        y_train (pandas.Series): Training target.\n",
    "        X_val (csr_matrix): Validation Kinyarwanda text data.\n",
    "        y_val (pandas.Series): Validation target.\n",
    "        X_test (csr_matrix): Test Kinyarwanda text data.\n",
    "        y_test (pandas.Series): Test target.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the evaluation metrics.\n",
    "    \"\"\"\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    val_pred = model.predict(X_val)\n",
    "    val_acc = accuracy_score(y_val, val_pred)\n",
    "    val_f1 = f1_score(y_val, val_pred, average='weighted')\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_pred = model.predict(X_test)\n",
    "    test_acc = accuracy_score(y_test, test_pred)\n",
    "    test_f1 = f1_score(y_test, test_pred, average='weighted')\n",
    "\n",
    "    return {\n",
    "        'val_accuracy': val_acc,\n",
    "        'val_f1': val_f1,\n",
    "        'test_accuracy': test_acc,\n",
    "        'test_f1': test_f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncertainty_score(model, X):\n",
    "    \"\"\"\n",
    "    Compute the uncertainty score for a given sample.\n",
    "\n",
    "    Args:\n",
    "        model: The machine learning model to be used for uncertainty estimation.\n",
    "        X (csr_matrix): The input sample.\n",
    "\n",
    "    Returns:\n",
    "        float: The uncertainty score for the input sample.\n",
    "    \"\"\"\n",
    "    # Standardize the input sample\n",
    "    scaler = StandardScaler(with_mean=False)\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Compute the probability of the predicted class\n",
    "    y_pred_prob = model.predict_proba(X_scaled)[0]\n",
    "\n",
    "    # Compute the uncertainty score as the negative of the maximum probability\n",
    "    uncertainty_score = -max(y_pred_prob)\n",
    "\n",
    "    return uncertainty_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark the model without data augmentation\n",
    "model = LogisticRegression()\n",
    "baseline_metrics = benchmark_model(model, X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "print(\"Baseline metrics:\", baseline_metrics)\n",
    "\n",
    "# Benchmark the model with LADA data augmentation\n",
    "X_train_augmented, y_train_augmented = lada_kinyarwanda_tsv(X_train, y_train, model)\n",
    "model = LogisticRegression()\n",
    "augmented_metrics = benchmark_model(model, X_train_augmented, y_train_augmented, X_val, y_val, X_test, y_test)\n",
    "print(\"Augmented metrics:\", augmented_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
