{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"UBC-NLP/serengeti-E250\", token=\"XXX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForMaskedLM were not initialized from the model checkpoint at UBC-NLP/serengeti-E250 and are newly initialized: ['generator_lm_head.bias', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias', 'generator_predictions.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForMaskedLM.from_pretrained(\"UBC-NLP/serengeti-E250\", token=\"XXX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElectraForMaskedLM(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(250000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (generator_predictions): ElectraGeneratorPredictions(\n",
       "    (activation): GELUActivation()\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "  )\n",
       "  (generator_lm_head): Linear(in_features=768, out_features=250000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.0002651364484336227,\n",
       "  'token': 185120,\n",
       "  'token_str': 'akabaki',\n",
       "  'sequence': 'e jowo, e akabaki mi'},\n",
       " {'score': 0.00019752785738091916,\n",
       "  'token': 4820,\n",
       "  'token_str': '##pote',\n",
       "  'sequence': 'e jowo, epote mi'},\n",
       " {'score': 0.00019085600797552615,\n",
       "  'token': 59489,\n",
       "  'token_str': 'performed',\n",
       "  'sequence': 'e jowo, e performed mi'},\n",
       " {'score': 0.0001901101932162419,\n",
       "  'token': 209347,\n",
       "  'token_str': 'maizi',\n",
       "  'sequence': 'e jowo, e maizi mi'},\n",
       " {'score': 0.0001779572485247627,\n",
       "  'token': 174811,\n",
       "  'token_str': 'contributors',\n",
       "  'sequence': 'e jowo, e contributors mi'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"fill-mask\", model=model, tokenizer=tokenizer)\n",
    "classifier(\"·∫π j·ªçw·ªç , ·∫π [MASK] mi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kr_train_00001</td>\n",
       "      <td>@user @user @user @user @user @user @user Hhhh...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kr_train_00002</td>\n",
       "      <td>@user Amahano?! Ni impanuka, inkangu, inzara.....</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kr_train_00003</td>\n",
       "      <td>Ese umuntu aguhaye miliyoni 7 zidorali ngo ary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kr_train_00004</td>\n",
       "      <td>Ugira amagamboüòè kandi Ubwo wasanga nawe byagut...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kr_train_00005</td>\n",
       "      <td>Ukuntu inama zose zikomeye zirikubera Mu Rwand...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3297</th>\n",
       "      <td>kr_train_03298</td>\n",
       "      <td>Tugukunda kurusha mukobwa mwiza! Amahoro, ibyi...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3298</th>\n",
       "      <td>kr_train_03299</td>\n",
       "      <td>*Sobanukirwa IBYIZA MASSAGE IFITEYE UMUBIRI* üëâ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3299</th>\n",
       "      <td>kr_train_03300</td>\n",
       "      <td>Mushobora kugira uruhare muri iki kiganiro mut...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3300</th>\n",
       "      <td>kr_train_03301</td>\n",
       "      <td>2/2 Ntuduhane mu bitwoshya, Ahubwo udukize Umu...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3301</th>\n",
       "      <td>kr_train_03302</td>\n",
       "      <td>@user @user @user @user @user @user Ni umuyobo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3302 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID                                              tweet  \\\n",
       "0     kr_train_00001  @user @user @user @user @user @user @user Hhhh...   \n",
       "1     kr_train_00002  @user Amahano?! Ni impanuka, inkangu, inzara.....   \n",
       "2     kr_train_00003  Ese umuntu aguhaye miliyoni 7 zidorali ngo ary...   \n",
       "3     kr_train_00004  Ugira amagamboüòè kandi Ubwo wasanga nawe byagut...   \n",
       "4     kr_train_00005  Ukuntu inama zose zikomeye zirikubera Mu Rwand...   \n",
       "...              ...                                                ...   \n",
       "3297  kr_train_03298  Tugukunda kurusha mukobwa mwiza! Amahoro, ibyi...   \n",
       "3298  kr_train_03299  *Sobanukirwa IBYIZA MASSAGE IFITEYE UMUBIRI* üëâ...   \n",
       "3299  kr_train_03300  Mushobora kugira uruhare muri iki kiganiro mut...   \n",
       "3300  kr_train_03301  2/2 Ntuduhane mu bitwoshya, Ahubwo udukize Umu...   \n",
       "3301  kr_train_03302  @user @user @user @user @user @user Ni umuyobo...   \n",
       "\n",
       "         label  \n",
       "0     negative  \n",
       "1     negative  \n",
       "2     negative  \n",
       "3     negative  \n",
       "4     negative  \n",
       "...        ...  \n",
       "3297  positive  \n",
       "3298  positive  \n",
       "3299  positive  \n",
       "3300  positive  \n",
       "3301  positive  \n",
       "\n",
       "[3302 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"kr_train.tsv\", sep=\"\\t\")\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kr_test_00001</td>\n",
       "      <td>@user @user @user Kubeshya ntabwo Ari icyaha u...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kr_test_00002</td>\n",
       "      <td>@user Itegeko ry'umuryango rivuga ko n'umugore...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kr_test_00003</td>\n",
       "      <td>Abafollowers ba byimbisha intugu ba @user @use...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kr_test_00004</td>\n",
       "      <td>@user @user Aha niho bita ku kirenge ra?</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kr_test_00005</td>\n",
       "      <td>Hari abantu bahisemo brain kuyikoresha nk‚Äôamas...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>kr_test_01028</td>\n",
       "      <td>@user Kuki wumva ko ibicuruzwa byo Mugihugu cy...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>kr_test_01030</td>\n",
       "      <td>@user @user @user @user @user @user @user Bina...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>kr_test_01032</td>\n",
       "      <td>Amahoro mwese bantu ba hano,Uyu munsi Imana ib...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>kr_test_01033</td>\n",
       "      <td>@user Gus buriya ninkikibazo jyanibaza burigih...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>kr_test_01034</td>\n",
       "      <td>@user Hanyuma se izo ni inka muzakama!?üòèüòè arik...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1026 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID                                              tweet  \\\n",
       "0     kr_test_00001  @user @user @user Kubeshya ntabwo Ari icyaha u...   \n",
       "1     kr_test_00002  @user Itegeko ry'umuryango rivuga ko n'umugore...   \n",
       "2     kr_test_00003  Abafollowers ba byimbisha intugu ba @user @use...   \n",
       "3     kr_test_00004           @user @user Aha niho bita ku kirenge ra?   \n",
       "4     kr_test_00005  Hari abantu bahisemo brain kuyikoresha nk‚Äôamas...   \n",
       "...             ...                                                ...   \n",
       "1021  kr_test_01028  @user Kuki wumva ko ibicuruzwa byo Mugihugu cy...   \n",
       "1022  kr_test_01030  @user @user @user @user @user @user @user Bina...   \n",
       "1023  kr_test_01032  Amahoro mwese bantu ba hano,Uyu munsi Imana ib...   \n",
       "1024  kr_test_01033  @user Gus buriya ninkikibazo jyanibaza burigih...   \n",
       "1025  kr_test_01034  @user Hanyuma se izo ni inka muzakama!?üòèüòè arik...   \n",
       "\n",
       "         label  \n",
       "0      neutral  \n",
       "1      neutral  \n",
       "2     negative  \n",
       "3      neutral  \n",
       "4     negative  \n",
       "...        ...  \n",
       "1021   neutral  \n",
       "1022   neutral  \n",
       "1023  positive  \n",
       "1024   neutral  \n",
       "1025   neutral  \n",
       "\n",
       "[1026 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"kr_test.tsv\", sep=\"\\t\")\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "\n",
    "    text = re.sub(r'http\\S+|www.\\S+|@\\w+', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['tweet'] = train_data['tweet'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          Hhhhhh ntabyihogoza ubu x abo yishe bangana ik\n",
       "1       Amahano Ni impanuka inkangu inzara Muyite izin...\n",
       "2       Ese umuntu aguhaye miliyoni 7 zidorali ngo ary...\n",
       "3       Ugira amagambo kandi Ubwo wasanga nawe byaguta...\n",
       "4       Ukuntu inama zose zikomeye zirikubera Mu Rwand...\n",
       "                              ...                        \n",
       "3297    Tugukunda kurusha mukobwa mwiza Amahoro ibyish...\n",
       "3298    Sobanukirwa IBYIZA MASSAGE IFITEYE UMUBIRI   h...\n",
       "3299    Mushobora kugira uruhare muri iki kiganiro mut...\n",
       "3300    22 Ntuduhane mu bitwoshya Ahubwo udukize Umubi...\n",
       "3301    Ni umuyobozi wintangarugero aho ageze hose Ni ...\n",
       "Name: tweet, Length: 3302, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['tweet']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting sentences for augmentatiom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "660"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "num_sentences = int(len(train_data)*0.2)\n",
    "\n",
    "random_indexes = random.sample(range(len(train_data)), num_sentences)\n",
    "\n",
    "len(random_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sosiyete yubucuruzi ikandika icyapa kinini cyane iti Guhamagara nubuntu  kandi bashaka kuvuga ngo Guhamagara ni ubuntu Birababaza negative\n"
     ]
    }
   ],
   "source": [
    "random_sentences = train_data.loc[random_indexes, \"tweet\"].tolist()\n",
    "random_labels = train_data.loc[random_indexes, \"label\"].tolist()\n",
    "\n",
    "print(random_sentences[0], random_labels[0]) # read random sentences and corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masked :  [MASK] yubucuruzi ikandika icyapa kinini cyane iti Guhamagara nubuntu kandi bashaka kuvuga ngo Guhamagara ni ubuntu Birababaza\n",
      "predicted :  gewag yubucuruzi ikandika icyapa kinini cyane iti Guhamagara nubuntu kandi bashaka kuvuga ngo Guhamagara ni ubuntu Birababaza\n",
      "masked :  gewag [MASK] ikandika icyapa kinini cyane iti Guhamagara nubuntu kandi bashaka kuvuga ngo Guhamagara ni ubuntu Birababaza\n",
      "predicted :  gewag fighter ikandika icyapa kinini cyane iti Guhamagara nubuntu kandi bashaka kuvuga ngo Guhamagara ni ubuntu Birababaza\n",
      "masked :  gewag fighter [MASK] icyapa kinini cyane iti Guhamagara nubuntu kandi bashaka kuvuga ngo Guhamagara ni ubuntu Birababaza\n",
      "predicted :  gewag fighter wafana icyapa kinini cyane iti Guhamagara nubuntu kandi bashaka kuvuga ngo Guhamagara ni ubuntu Birababaza\n",
      "masked :  gewag fighter wafana [MASK] kinini cyane iti Guhamagara nubuntu kandi bashaka kuvuga ngo Guhamagara ni ubuntu Birababaza\n",
      "predicted :  gewag fighter wafana fighter kinini cyane iti Guhamagara nubuntu kandi bashaka kuvuga ngo Guhamagara ni ubuntu Birababaza\n",
      "masked :  gewag fighter wafana fighter [MASK] cyane iti Guhamagara nubuntu kandi bashaka kuvuga ngo Guhamagara ni ubuntu Birababaza\n",
      "predicted :  gewag fighter wafana fighter fighter cyane iti Guhamagara nubuntu kandi bashaka kuvuga ngo Guhamagara ni ubuntu Birababaza\n",
      "masked :  gewag fighter wafana fighter fighter [MASK] iti Guhamagara nubuntu kandi bashaka kuvuga ngo Guhamagara ni ubuntu Birababaza\n",
      "predicted :  gewag fighter wafana fighter fighter jiif iti Guhamagara nubuntu kandi bashaka kuvuga ngo Guhamagara ni ubuntu Birababaza\n",
      "masked :  gewag fighter wafana fighter fighter jiif [MASK] Guhamagara nubuntu kandi bashaka kuvuga ngo Guhamagara ni ubuntu Birababaza\n",
      "predicted :  gewag fighter wafana fighter fighter jiif limu Guhamagara nubuntu kandi bashaka kuvuga ngo Guhamagara ni ubuntu Birababaza\n",
      "masked :  gewag fighter wafana fighter fighter jiif limu [MASK] nubuntu kandi bashaka kuvuga ngo Guhamagara ni ubuntu Birababaza\n",
      "predicted :  gewag fighter wafana fighter fighter jiif limu wafana nubuntu kandi bashaka kuvuga ngo Guhamagara ni ubuntu Birababaza\n",
      "masked :  gewag fighter wafana fighter fighter jiif limu wafana [MASK] kandi bashaka kuvuga ngo Guhamagara ni ubuntu Birababaza\n",
      "predicted :  gewag fighter wafana fighter fighter jiif limu wafana lafi kandi bashaka kuvuga ngo Guhamagara ni ubuntu Birababaza\n",
      "masked :  gewag fighter wafana fighter fighter jiif limu wafana lafi [MASK] bashaka kuvuga ngo Guhamagara ni ubuntu Birababaza\n",
      "predicted :  gewag fighter wafana fighter fighter jiif limu wafana lafi fighter bashaka kuvuga ngo Guhamagara ni ubuntu Birababaza\n",
      "masked :  gewag fighter wafana fighter fighter jiif limu wafana lafi fighter [MASK] kuvuga ngo Guhamagara ni ubuntu Birababaza\n",
      "predicted :  gewag fighter wafana fighter fighter jiif limu wafana lafi fighter ulipangwa kuvuga ngo Guhamagara ni ubuntu Birababaza\n",
      "masked :  gewag fighter wafana fighter fighter jiif limu wafana lafi fighter ulipangwa [MASK] ngo Guhamagara ni ubuntu Birababaza\n",
      "predicted :  gewag fighter wafana fighter fighter jiif limu wafana lafi fighter ulipangwa wafana ngo Guhamagara ni ubuntu Birababaza\n",
      "masked :  gewag fighter wafana fighter fighter jiif limu wafana lafi fighter ulipangwa wafana [MASK] Guhamagara ni ubuntu Birababaza\n",
      "predicted :  gewag fighter wafana fighter fighter jiif limu wafana lafi fighter ulipangwa wafana gewag Guhamagara ni ubuntu Birababaza\n",
      "masked :  gewag fighter wafana fighter fighter jiif limu wafana lafi fighter ulipangwa wafana gewag [MASK] ni ubuntu Birababaza\n",
      "predicted :  gewag fighter wafana fighter fighter jiif limu wafana lafi fighter ulipangwa wafana gewag gewag ni ubuntu Birababaza\n",
      "masked :  gewag fighter wafana fighter fighter jiif limu wafana lafi fighter ulipangwa wafana gewag gewag [MASK] ubuntu Birababaza\n",
      "predicted :  gewag fighter wafana fighter fighter jiif limu wafana lafi fighter ulipangwa wafana gewag gewag broadcast ubuntu Birababaza\n",
      "masked :  gewag fighter wafana fighter fighter jiif limu wafana lafi fighter ulipangwa wafana gewag gewag broadcast [MASK] Birababaza\n",
      "predicted :  gewag fighter wafana fighter fighter jiif limu wafana lafi fighter ulipangwa wafana gewag gewag broadcast limu Birababaza\n",
      "masked :  gewag fighter wafana fighter fighter jiif limu wafana lafi fighter ulipangwa wafana gewag gewag broadcast limu [MASK]\n",
      "predicted :  gewag fighter wafana fighter fighter jiif limu wafana lafi fighter ulipangwa wafana gewag gewag broadcast limu cop\n"
     ]
    }
   ],
   "source": [
    "# iterative mask filling\n",
    "\n",
    "sentence = random_sentences[0]\n",
    "\n",
    "words = sentence.split()\n",
    "length = len(words)\n",
    "\n",
    "new_sentence = sentence\n",
    "\n",
    "for i in range(0, length):\n",
    "    words_new = new_sentence.split()\n",
    "    words_new[i] = \"[MASK]\"\n",
    "    masked_sentence = \" \".join(words_new)\n",
    "    print(\"masked : \", masked_sentence)\n",
    "    predictions = classifier(masked_sentence)\n",
    "    predicted_token = predictions[0]['token_str']\n",
    "    new_sentence = masked_sentence.replace(\"[MASK]\", predicted_token, 1)\n",
    "    print(\"predicted : \", new_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split sentences into words\n",
    "# mask one word\n",
    "# pass the sentence to the model\n",
    "# get the prediction\n",
    "# replace sentence with predicted sentence\n",
    "# repeat\n",
    "# return new sentence\n",
    "\n",
    "\n",
    "def iterative_mask_fill(sentence):\n",
    "    try:\n",
    "        words = sentence.split()\n",
    "        length = len(words)\n",
    "\n",
    "        new_sentence = sentence\n",
    "\n",
    "        for i in range(0, length):\n",
    "\n",
    "            words_new = new_sentence.split()\n",
    "            words_new[i] = \"[MASK]\" # mask ith word\n",
    "\n",
    "            masked_sentence = \" \".join(words_new)\n",
    "\n",
    "            prediction = classifier(masked_sentence)\n",
    "            prediction = prediction[0][\"token_str\"]\n",
    "\n",
    "            new_sentence = masked_sentence.replace(\"[MASK]\", prediction, 1)\n",
    "            \n",
    "\n",
    "        return new_sentence\n",
    "    \n",
    "    except:\n",
    "        print(f\"error at iteration {i}\")\n",
    "        return random_mask_fill(sentence)\n",
    "\n",
    "# select random word in sentence\n",
    "# replace with mask\n",
    "# pass to model\n",
    "# get prediction\n",
    "# replace sentence with prediction\n",
    "# return new sentence\n",
    "\n",
    "def random_mask_fill(sentence):\n",
    "\n",
    "    words = sentence.split()\n",
    "    length = len(words)\n",
    "\n",
    "    new_sentence = [] # empty new sentence\n",
    "\n",
    "    index = random.randint(0, length-1)\n",
    "\n",
    "    words_new = sentence.split()\n",
    "\n",
    "    words_new[index] = \"[MASK]\" # mask random word\n",
    "\n",
    "    masked_sentence = \" \".join(words_new)\n",
    "\n",
    "    prediction = classifier(masked_sentence)\n",
    "\n",
    "    prediction = prediction[0]['token_str']\n",
    "\n",
    "    new_sentence = masked_sentence.replace(\"[MASK]\", prediction)\n",
    "\n",
    "    return new_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sosiyete yubucuruzi ikandika icyapa kinini cyane iti Guhamagara nubuntu  kandi bashaka kuvuga ngo Guhamagara ni ubuntu Birababaza\n"
     ]
    }
   ],
   "source": [
    "print(random_sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gewag fighter wafana fighter fighter jiif limu wafana lafi fighter ulipangwa wafana gewag gewag broadcast limu cop\n",
      "Sosiyete yubucuruzi ikandika icyapa gewag cyane iti Guhamagara nubuntu kandi bashaka kuvuga ngo Guhamagara ni ubuntu Birababaza\n"
     ]
    }
   ],
   "source": [
    "print(iterative_mask_fill(random_sentences[0]))\n",
    "print(random_mask_fill(random_sentences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    new_sentences_iter = [iterative_mask_fill(sentence) for sentence in random_sentences]\n",
    "    new_sentences_rand = [random_mask_fill(sentence) for sentence in random_sentences]\n",
    "except Exception:\n",
    "    print(\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gewag fighter wafana fighter fighter jiif limu wafana lafi fighter ulipangwa wafana gewag gewag broadcast limu cop\n",
      "Sosiyete yubucuruzi ikandika icyapa kinini cyane iti Guhamagara nubuntu kandi bashaka gewag ngo Guhamagara ni ubuntu Birababaza\n"
     ]
    }
   ],
   "source": [
    "print(new_sentences_iter[0])\n",
    "print(new_sentences_rand[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 ID                                              tweet  \\\n",
      "0    kr_train_03303  gewag fighter wafana fighter fighter jiif limu...   \n",
      "1    kr_train_03304         ulipangwa ommy ommy tumepanga kunyunyi jak   \n",
      "2    kr_train_03305              lafi lafi wafana ommy wafana kumlisha   \n",
      "3    kr_train_03306  ulipangwa jiif walid ommy limu wafana lafi laf...   \n",
      "4    kr_train_03307  limu limu limu limu limu limu limu limu limu l...   \n",
      "..              ...                                                ...   \n",
      "655  kr_train_03958            ulipangwa ommy fighter fighter ommy cop   \n",
      "656  kr_train_03959  ulipangwa ommy limu fighter wafana gewag lafi ...   \n",
      "657  kr_train_03960  behavior wafana wafana wafana wafana wafana wa...   \n",
      "658  kr_train_03961  ##nin grana viewers limu broadcast limu ulipan...   \n",
      "659  kr_train_03962                ##washu wafana broadcast panel lafi   \n",
      "\n",
      "        label  \n",
      "0    negative  \n",
      "1     neutral  \n",
      "2    negative  \n",
      "3    negative  \n",
      "4     neutral  \n",
      "..        ...  \n",
      "655  positive  \n",
      "656  negative  \n",
      "657  negative  \n",
      "658  positive  \n",
      "659   neutral  \n",
      "\n",
      "[660 rows x 3 columns]\n",
      "                 ID                                              tweet  \\\n",
      "0    kr_train_03303  Sosiyete yubucuruzi ikandika icyapa kinini cya...   \n",
      "1    kr_train_03304            ulipangwa se wa mico utweretse haruguru   \n",
      "2    kr_train_03305                Yanze kubyumva ubumenyi bw isi limu   \n",
      "3    kr_train_03306  Mbese muzaza cg aya mata nzayanywa njyenyine n...   \n",
      "4    kr_train_03307  Madamu wa Perezida wa Repubulika Jeannette Kag...   \n",
      "..              ...                                                ...   \n",
      "655  kr_train_03958    Umwana uzi ubwenge bamusiga kunyunyi yinogereza   \n",
      "656  kr_train_03959  Ni fighter mumaraso Amazuru yabo abayarasabits...   \n",
      "657  kr_train_03960  Urebe ibyo yagiye yivugira nyamara ntimugapfe ...   \n",
      "658  kr_train_03961  Nibyo kabsa bro Aho tubyumva kimwe tanu ##wate...   \n",
      "659  kr_train_03962                       Uyu muvugo alaf mbona volume   \n",
      "\n",
      "        label  \n",
      "0    negative  \n",
      "1     neutral  \n",
      "2    negative  \n",
      "3    negative  \n",
      "4     neutral  \n",
      "..        ...  \n",
      "655  positive  \n",
      "656  negative  \n",
      "657  negative  \n",
      "658  positive  \n",
      "659   neutral  \n",
      "\n",
      "[660 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iter = pd.DataFrame({'ID': ['kr_train_0' + str(i+3303) for i in range(len(new_sentences_iter))],\n",
    "                       'tweet': new_sentences_iter,\n",
    "                       'label': random_labels})\n",
    "rand = pd.DataFrame({'ID': ['kr_train_0' + str(i+3303) for i in range(len(new_sentences_rand))],\n",
    "                       'tweet': new_sentences_rand,\n",
    "                       'label': random_labels})\n",
    "\n",
    "iter = iter[['ID', 'tweet', 'label']]\n",
    "rand = rand[['ID', 'tweet', 'label']]\n",
    "\n",
    "print(iter)\n",
    "print(rand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the augmented sentences to original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "augmented_iter = pd.concat([train_data, iter], axis=0)\n",
    "augmented_rand = pd.concat([train_data, rand], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_iter.to_csv(\"kr_train_iter.tsv\", sep=\"\\t\", index=False)\n",
    "augmented_rand.to_csv(\"kr_train_rand.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference\n",
    "\n",
    "[SERENGETI: Massively Multilingual Language Models for Africa](https://arxiv.org/pdf/2212.10785)\n",
    "\n",
    "[XLM-E: Cross-lingual Language Model Pre-training via ELECTRA](https://aclanthology.org/2022.acl-long.427.pdf)\n",
    "\n",
    "[Unsupervised Cross-lingual Representation Learning at Scale](https://aclanthology.org/2020.acl-main.747.pdf)\n",
    "\n",
    "[Iterative Mask Filling: An Effective Text Augmentation Method Using Masked Language Modeling](https://arxiv.org/abs/2401.01830)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "augment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
